# è®­ç»ƒæŒ‡å—å’Œé—®é¢˜è¯Šæ–­

## ğŸ”´ å·²ä¿®å¤çš„å…³é”®Bug

### Bug 1: è‡ªå›å½’ç”Ÿæˆé€»è¾‘é”™è¯¯ (CRITICAL)
**ä½ç½®:** `3_model.py:125` (åŸä»£ç )

**é—®é¢˜:**
```python
t = torch.concat((t, ti[:,i:]), dim=1)  # âŒ é”™è¯¯ï¼
```

- å½“ `i=0` æ—¶ï¼š`ti[:,0:]` è·å–**æ•´ä¸ª**decoderè¾“å‡ºåºåˆ—
- å½“ `i=1` æ—¶ï¼š`ti[:,1:]` è·å–éƒ¨åˆ†åºåˆ—
- å¯¼è‡´åºåˆ—é•¿åº¦å¢é•¿ä¸è§„åˆ™ï¼Œè®­ç»ƒå®Œå…¨å´©æºƒ

**ä¿®å¤:**
```python
next_token = ti[:, -1:, :]  # âœ… åªå–æœ€åä¸€ä¸ªé¢„æµ‹
t = torch.cat((t, next_token), dim=1)
```

**å½±å“:** è¿™æ˜¯å¯¼è‡´ä½ è®­ç»ƒå´©æºƒçš„**ä¸»è¦åŸå› **ï¼

---

## ğŸ› ï¸ è®­ç»ƒç¨³å®šæ€§æ”¹è¿›

### 1. æƒé‡åˆå§‹åŒ–
```python
# ä½¿ç”¨Xavieråˆå§‹åŒ–ï¼Œgain=0.5ï¼ˆæ›´ä¿å®ˆï¼‰
torch.nn.init.xavier_uniform_(m.weight, gain=0.5)
```

### 2. æ¢¯åº¦è£å‰ª
```python
# ä» max_norm=10.0 æ”¹ä¸º 1.0ï¼ˆæ›´ä¸¥æ ¼ï¼‰
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
```

### 3. å­¦ä¹ ç‡ç­–ç•¥
```python
# é»˜è®¤å­¦ä¹ ç‡ï¼š0.001 â†’ 0.0005ï¼ˆæ›´ä¿å®ˆï¼‰
# Warmupè½®æ•°ï¼š5 â†’ 10ï¼ˆæ›´é•¿ï¼‰
# Warmupèµ·å§‹ï¼š0.1x â†’ 0.01xï¼ˆæ›´æ¸©å’Œï¼‰
# æœ€ç»ˆå­¦ä¹ ç‡ï¼š0.0001 â†’ 0.00001
```

**å®é™…å­¦ä¹ ç‡æ›²çº¿ï¼š**
- Epoch 0: 0.000005 (0.0005 * 0.01)
- Epoch 5: 0.00025 (çº¿æ€§å¢é•¿ä¸­)
- Epoch 10: 0.0005 (è¾¾åˆ°åˆå§‹LR)
- Epoch 100: 0.00001 (cosineè¡°å‡åˆ°æœ€å°)

### 4. æ­£åˆ™åŒ–
```python
# æ·»åŠ weight decay
optimizer = torch.optim.AdamW(..., weight_decay=0.01)
```

---

## ğŸ“Š è®­ç»ƒç›‘æ§

### æ­£å¸¸çš„è®­ç»ƒæ›²çº¿åº”è¯¥æ˜¯ï¼š
âœ… **å‰10è½® (Warmup):**
- Train loss: ç¼“æ…¢ä¸‹é™
- Val loss: ç¼“æ…¢ä¸‹é™æˆ–ä¿æŒå¹³ç¨³
- å­¦ä¹ ç‡: ä»0.000005é€æ¸å¢é•¿åˆ°0.0005

âœ… **10è½®å (Main Training):**
- Train loss: æŒç»­ä¸‹é™
- Val loss: ä¸‹é™ï¼Œå¯èƒ½åœ¨åæœŸç•¥å¾®ä¸Šå‡ï¼ˆæ­£å¸¸çš„è¿‡æ‹Ÿåˆï¼‰
- å­¦ä¹ ç‡: ä»0.0005æŒ‰ä½™å¼¦æ›²çº¿è¡°å‡

### å¼‚å¸¸æƒ…å†µå’Œè§£å†³æ–¹æ³•ï¼š

#### ğŸ”´ æƒ…å†µ1: Lossçˆ†ç‚¸ï¼ˆå˜æˆNaNæˆ–æ€¥å‰§å¢å¤§ï¼‰
**åŸå› :** å­¦ä¹ ç‡å¤ªå¤§æˆ–æ¢¯åº¦çˆ†ç‚¸
**è§£å†³:**
```bash
# é™ä½å­¦ä¹ ç‡
python 3_train.py --lr-init 0.0001

# æˆ–æ›´ä¸¥æ ¼çš„æ¢¯åº¦è£å‰ªï¼ˆä¿®æ”¹ä»£ç ä¸­çš„max_normï¼‰
```

#### ğŸ”´ æƒ…å†µ2: Lossä¸ä¸‹é™ï¼ˆä¿æŒé«˜ä½ï¼‰
**åŸå› :** å­¦ä¹ ç‡å¤ªå°æˆ–æ¨¡å‹åˆå§‹åŒ–ä¸å¥½
**è§£å†³:**
```bash
# å¢åŠ å­¦ä¹ ç‡
python 3_train.py --lr-init 0.001

# æˆ–è°ƒæ•´batch size
python 3_train.py --batch-size 64
```

#### ğŸ”´ æƒ…å†µ3: Val lossä¸Šå‡ä½†Train lossä¸‹é™
**åŸå› :** è¿‡æ‹Ÿåˆ
**è§£å†³:**
- æ—©åœä¼šè‡ªåŠ¨å¤„ç†ï¼ˆpatience=10ï¼‰
- å¯ä»¥å¢åŠ dropoutæˆ–å‡å°‘æ¨¡å‹å±‚æ•°

---

## ğŸš€ æ¨èçš„è®­ç»ƒå‘½ä»¤

### åŸºç¡€è®­ç»ƒï¼ˆæ¨èæ–°æ‰‹ï¼‰
```bash
python 3_train.py \
    --epochs 100 \
    --batch-size 48 \
    --lr-init 0.0005 \
    --device 0
```

### å¿«é€Ÿå®éªŒï¼ˆæµ‹è¯•ä»£ç ï¼‰
```bash
python 3_train.py \
    --epochs 20 \
    --batch-size 64 \
    --subset 0.1 \
    --device 0
```

### å®Œæ•´è®­ç»ƒï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
```bash
python 3_train.py \
    --epochs 200 \
    --batch-size 32 \
    --lr-init 0.0005 \
    --lr-final 0.00001 \
    --hidden-feat-size 256 \
    --device 0
```

### ä»æ£€æŸ¥ç‚¹æ¢å¤
```bash
python 3_train.py \
    --resume checkpoint_epoch10.pth \
    --epochs 200 \
    --device 0
```

---

## ğŸ“ˆ æŸ¥çœ‹è®­ç»ƒè¿›åº¦

### æ–¹æ³•1: å®æ—¶ç›‘æ§ï¼ˆæ¨èï¼‰
```bash
# ç»ˆç«¯1: å¯åŠ¨è®­ç»ƒ
python 3_train.py

# ç»ˆç«¯2: å¯åŠ¨TensorBoard
tensorboard --logdir=runs --port=6006

# æµè§ˆå™¨æ‰“å¼€: http://localhost:6006
```

### æ–¹æ³•2: æŸ¥çœ‹æ—¥å¿—æ‘˜è¦
```bash
python view_tensorboard_logs.py runs
```

---

## ğŸ¯ è¶…å‚æ•°è°ƒä¼˜å»ºè®®

### å¦‚æœæ¨¡å‹æ¬ æ‹Ÿåˆï¼ˆtrain lossè¿˜å¾ˆé«˜ï¼‰:
1. â¬†ï¸ å¢åŠ æ¨¡å‹å®¹é‡ï¼š`--hidden-feat-size 512`
2. â¬†ï¸ å¢åŠ å­¦ä¹ ç‡ï¼š`--lr-init 0.001`
3. â¬†ï¸ å‡å°‘æ­£åˆ™åŒ–ï¼šä¿®æ”¹ä»£ç ä¸­çš„`weight_decay=0.001`

### å¦‚æœæ¨¡å‹è¿‡æ‹Ÿåˆï¼ˆval loss >> train lossï¼‰:
1. â¬‡ï¸ å‡å°‘æ¨¡å‹å®¹é‡ï¼š`--hidden-feat-size 128`
2. â¬‡ï¸ å‡å°‘å­¦ä¹ ç‡ï¼š`--lr-init 0.0003`
3. â¬†ï¸ å¢åŠ dropoutï¼šä¿®æ”¹ä»£ç ä¸­çš„`Dropout(0.2)`
4. â¬†ï¸ å¢åŠ æ­£åˆ™åŒ–ï¼šä¿®æ”¹ä»£ç ä¸­çš„`weight_decay=0.05`

### å¦‚æœè®­ç»ƒå¤ªæ…¢:
1. â¬†ï¸ å¢åŠ batch sizeï¼š`--batch-size 64` æˆ– `128`
2. â¬‡ï¸ å‡å°‘workersï¼š`--num-workers 2`ï¼ˆå¦‚æœCPUæ˜¯ç“¶é¢ˆï¼‰
3. â¬‡ï¸ ä½¿ç”¨æ•°æ®å­é›†æµ‹è¯•ï¼š`--subset 0.5`

---

## ğŸ› å¸¸è§é”™è¯¯

### CUDA Out of Memory
```bash
# å‡å°batch size
python 3_train.py --batch-size 24

# æˆ–å‡å°æ¨¡å‹
python 3_train.py --hidden-feat-size 128
```

### RuntimeError: expected scalar type Float but found Double
```bash
# æ•°æ®ç±»å‹é—®é¢˜ï¼Œæ£€æŸ¥data.csvæ˜¯å¦æ­£ç¡®
# ç¡®ä¿ä½¿ç”¨ np.float32
```

### Losså˜æˆNaN
```bash
# é™ä½å­¦ä¹ ç‡å¹¶ä½¿ç”¨æ›´ä¸¥æ ¼çš„æ¢¯åº¦è£å‰ª
python 3_train.py --lr-init 0.0001
```

---

## ğŸ“ æ£€æŸ¥ç‚¹è¯´æ˜

è®­ç»ƒä¼šè‡ªåŠ¨ä¿å­˜ï¼š
- `checkpoint_epoch{N}.pth` - æ¯ä¸ªepochçš„æ£€æŸ¥ç‚¹
- `best_checkpoint_epoch{N}.pth` - éªŒè¯é›†ä¸Šè¡¨ç°æœ€å¥½çš„æ£€æŸ¥ç‚¹

æ¯ä¸ªæ£€æŸ¥ç‚¹åŒ…å«ï¼š
- `model_state_dict` - æ¨¡å‹æƒé‡
- `optimizer_state_dict` - ä¼˜åŒ–å™¨çŠ¶æ€
- `scheduler_state_dict` - å­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€
- `epoch` - å½“å‰è½®æ•°
- `val_loss` - éªŒè¯æŸå¤±
- `patience_counter` - æ—©åœè®¡æ•°å™¨

---

## âœ… ä¿®å¤éªŒè¯

ä¿®å¤åçš„é¢„æœŸè¡Œä¸ºï¼š
1. âœ… Train loss ç¨³å®šä¸‹é™ï¼ˆä¸ä¼šçªç„¶å¢å¤§ï¼‰
2. âœ… Val loss åœ¨å‰æœŸä¸‹é™æˆ–å¹³ç¨³
3. âœ… ä¸ä¼šåœ¨å‰10è½®å°±è§¦å‘æ—©åœ
4. âœ… æ¢¯åº¦èŒƒæ•°ä¿æŒåœ¨åˆç†èŒƒå›´ï¼ˆ< 10ï¼‰

å¦‚æœè¿˜æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
- [ ] æ•°æ®æ˜¯å¦æ­£ç¡®åŠ è½½ï¼ˆå½¢çŠ¶ã€æ•°å€¼èŒƒå›´ï¼‰
- [ ] GPUå†…å­˜æ˜¯å¦å……è¶³
- [ ] PyTorchç‰ˆæœ¬æ˜¯å¦å…¼å®¹ï¼ˆå»ºè®® >= 1.12ï¼‰
